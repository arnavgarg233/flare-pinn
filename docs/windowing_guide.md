# Windowing & Labeling Guide

## Overview

The `create_windows.py` script builds rolling input windows per NOAA Active Region (AR) from preprocessed frame metadata and produces classification targets at multiple prediction horizons.

## Prerequisites

1. **Frame Metadata**: Generated by `convert_and_preprocess_sharp.py`
   - Location: `data/interim/frames_meta.parquet`
   - Contains: `harpnum`, `date_obs`, `cmd_deg`, `frame_path`, normalization stats

2. **Flare Events**: Generated by `fetch_flares.py`
   - Location: `data/interim/flares_hek.parquet`
   - Contains: `start`, `peak`, `end`, `class`, `noaa_ar`

## Usage

### Basic Usage

```bash
python -m src.data.create_windows --cfg configs/data_train.yaml
```

### Custom Parameters

```bash
python -m src.data.create_windows \
  --cfg configs/data_train.yaml \
  --input-hours 48 \
  --stride-hours 6 \
  --horizons 6 12 24 \
  --cmd-threshold 70 \
  --partial-ok-frac 0.7
```

### Parameter Descriptions

- `--input-hours` (default: 48): Length of input history window in hours
- `--stride-hours` (default: 6): Stride between consecutive windows in hours
- `--horizons` (default: 6 12 24): Prediction horizons in hours (can specify multiple)
- `--cmd-threshold` (default: 70.0): Central Meridian Distance threshold for limb masking in degrees
- `--partial-ok-frac` (default: 0.7): Minimum fraction of horizon that must be observable to accept partial windows

## Output

### Windows Parquet

Location: `data/interim/windows.parquet`

Each row represents one window with columns:

**Window Metadata:**
- `harpnum`: NOAA AR identifier
- `t0`: Window end time (also start of prediction horizon)
- `input_span_hours`: Length of input window
- `stride_hours`: Stride used
- `horizons_hours`: List of prediction horizons
- `frame_count_in_window`: Number of frames in input window
- `obs_coverage`: Fraction of expected frames present (1h cadence assumption)
- `window_uid`: Unique identifier for this window

**Per-Horizon Columns** (for each horizon H in hours):
- `y_geq_M_{H}h`: Binary label (True if ≥M-class flare occurred)
- `event_count_{H}h`: Number of ≥M-class flares in [t0, t0+H)
- `is_masked_{H}h`: True if any part of horizon is limb-masked
- `is_partial_ok_{H}h`: True if horizon coverage ≥ partial_ok_frac
- `horizon_coverage_{H}h`: Fraction of horizon within CMD threshold

## Key Concepts

### Input Window
- Time range: `[t0 - input_hours, t0]`
- Contains historical magnetogram observations
- Expected cadence: 1 hour

### Prediction Horizon
- Time range: `[t0, t0 + H]` for horizon H
- Period for which we predict flare occurrence
- Multiple horizons can be specified

### Limb Censoring
- Active regions near the solar limb have foreshortening
- Windows are masked if `|CMD| > cmd_threshold`
- Prevents training on unreliable observations

### Observability
- Samples CMD at 1h intervals within horizon
- Computes fraction within threshold
- `is_partial_ok` flags windows with acceptable coverage

### Event Matching
- Flares matched to ARs via `noaa_ar` field from HEK
- Only ≥M-class flares are labeled (M and X class)
- Event counted if it starts within `[t0, t0+H)`

## Example Workflow

```bash
# 1. Fetch flare events (if not done)
python -m src.data.fetch_flares --cfg configs/data_train.yaml

# 2. Create windows with default parameters
python -m src.data.create_windows --cfg configs/data_train.yaml

# 3. Inspect results
python -c "
import pandas as pd
windows = pd.read_parquet('data/interim/windows.parquet')
print(f'Total windows: {len(windows)}')
print(f'Unique HARPs: {windows[\"harpnum\"].nunique()}')
print(f'Positive rate (24h): {windows[\"y_geq_M_24h\"].mean():.2%}')
"
```

## Quality Checks

After running, verify:
1. **Window count**: Should match expected (AR lifetime / stride)
2. **Coverage**: `obs_coverage` should be high (>0.8) for quality data
3. **Class balance**: Check positive rates per horizon
4. **Masking**: Review `is_masked_*` distributions

## Troubleshooting

**No windows generated:**
- Check that `frames_meta.parquet` exists and has data
- Verify ARs have sufficient observation history (≥ input_hours)

**Low obs_coverage:**
- Data gaps in magnetogram observations
- Consider increasing stride or reducing input_hours

**All labels negative:**
- Verify `flares_hek.parquet` has ≥M-class events
- Check time range overlap between frames and events
- Ensure `noaa_ar` field is populated in events

**Import errors:**
- Run from project root: `python -m src.data.create_windows ...`
- Ensure all dependencies installed (pydantic, pandas, numpy, click)

